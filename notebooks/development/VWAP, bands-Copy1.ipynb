{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from tmqr.settings import *\n",
    "from tmqrfeed import DataManager\n",
    "from pymongo import MongoClient\n",
    "from tmqrindex.index_base import IndexBase\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "#import cufflinks as cf\n",
    "#cf.go_offline()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "#import matplotlib\n",
    "#%matplotlib notebook\n",
    "\n",
    "figsize(15,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (pipeline, preprocessing, ensemble, neighbors, linear_model, neural_network, cluster, metrics, decomposition,\n",
    "                     naive_bayes, calibration, svm, multioutput,\n",
    "                     feature_selection, discriminant_analysis, model_selection, multiclass\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGO_CONNSTR)\n",
    "db = client[MONGO_DB]\n",
    "\n",
    "dm = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exo_list(exo_filter='*', return_names=True):\n",
    "    \"\"\"\n",
    "    Return EXO list stored in MongoDB V2\n",
    "    :param exo_filter: '*' - include all, wildcard is allowed (like, 'ES_Bullish*')\n",
    "    :param return_names: if True returns names list of EXO, otherwize returns MongoDB data collection list\n",
    "    :return: list of EXO names\n",
    "    \"\"\"\n",
    "    re_val = exo_filter.replace('*','.*')\n",
    "\n",
    "    data = db['index_data'].find({'name': re.compile(re_val, re.IGNORECASE)})\n",
    "    if return_names:\n",
    "        return [exo['name'] for exo in data]\n",
    "    else:\n",
    "        return list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_fisher_transform(series, transform_with='arctanh'):\n",
    "    '\"transform_with\" options - \"tanh\", \"arctanh\"'\n",
    "    \n",
    "    # Centering the series\n",
    "    series = series.expanding().apply(lambda x: preprocessing.StandardScaler().fit_transform(x.reshape(-1, 1)\n",
    "                                                                                                          ).ravel()[-1])\n",
    "\n",
    "    # limiting it to -0.999 > x < 0.999\n",
    "    series = series.expanding().apply(lambda x: preprocessing.MinMaxScaler(feature_range=(-0.999,0.999)\n",
    "                                                                                        ).fit_transform(x.reshape(-1, 1)).ravel()[-1])\n",
    "\n",
    "    if transform_with == 'arctanh':\n",
    "        ft_ser = np.arctanh(series)\n",
    "        \n",
    "    elif transform_with == 'tanh':\n",
    "        ft_ser = np.tanh(series)\n",
    "        \n",
    "    return ft_ser"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def universal_fisher_transform(series, scaling_period, transform_with='arctanh'):\n",
    "    '\"transform_with\" options - \"tanh\", \"arctanh\"'\n",
    "    \n",
    "    # Centering the series\n",
    "    series = series.rolling(int(scaling_period/2)).apply(lambda x: \n",
    "                                                         preprocessing.StandardScaler().fit_transform(x.reshape(-1, 1)\n",
    "                                                                                                     ).ravel()[-1])\n",
    "\n",
    "    # limiting it to -0.999 > x < 0.999\n",
    "    series = series.rolling(int(scaling_period/2)).apply(lambda x: \n",
    "                                                         preprocessing.MinMaxScaler(feature_range=(-0.999,0.999)\n",
    "                                                                                   ).fit_transform(x.reshape(-1, 1)\n",
    "                                                                                                  ).ravel()[-1])\n",
    "\n",
    "    \n",
    "    #return series\n",
    "\n",
    "    if transform_with == 'arctanh':\n",
    "        ft_ser = np.arctanh(series)\n",
    "        #ft_ser += 0.25 * ft_ser.shift(1)\n",
    "        #ft_ser += 0.5 * ft_ser.shift(1)\n",
    "        \n",
    "    elif transform_with == 'tanh':\n",
    "        ft_ser = np.tanh(series)\n",
    "        #ft_ser += 0.25 * ft_ser.shift(1)\n",
    "        #ft_ser += 0.5 * ft_ser.shift(1)\n",
    "        \n",
    "    return ft_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exo_filter = 'neutralOnly'     # All \n",
    "exo_filter = '*'  # ES only\n",
    "#exo_filter = '*'  # ES Collars (incl Bearish, Bullish, BW and vanilla)\n",
    "\n",
    "exo_dict = {}\n",
    "for exo in get_exo_list(exo_filter, return_names=False):\n",
    "    idx = IndexBase.deserialize(dm, exo, as_readonly=True)\n",
    "    exo_dict[idx.index_name] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exo_name, exo in exo_dict.items():\n",
    "    exo_df = exo.data\n",
    "    \n",
    "    if len(exo_df) < 200:\n",
    "        print(\"{0:<70} [NODATA DataLen: {1}]\".format(exo.index_name, len(exo_df)))\n",
    "    elif (datetime.now().date() - exo_df.index.date[-1]).days > 4:\n",
    "        print(\"{0:<70} [DELAYED: LastDate: {1}]\".format(exo.index_name, exo_df.index[-1]))\n",
    "    else:\n",
    "        print(\"{0:<70} [OK]\".format(exo.index_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_df = exo_dict['US.HO_ContFutEOD'].data.copy()\n",
    "\n",
    "#exo_df['c'] = ((exo_df.c - exo_df.c.ewm(100).mean()) / exo_df.c.ewm(100).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_move = exo_df.c > exo_df.c.shift(1)\n",
    "exo_df.loc[pos_move == True, 'v'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwap = ((exo_df.c * exo_df.v).cumsum() / (exo_df.v).cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_df.c.plot()\n",
    "vwap.plot(label='VWAP', legend=True)\n",
    "exo_df.c.expanding().mean().plot(label='Expanding mean', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(index=exo_df.index)\n",
    "\n",
    "for y in np.unique(exo_df.index.year):\n",
    "    exo_df_slice = exo_df[exo_df.index.year == y]\n",
    "    vwap_y = ((exo_df_slice.c * exo_df_slice.v).cumsum() / exo_df_slice.v.cumsum())\n",
    "\n",
    "    temp_df['vwap_yearly_{}'.format(y)] = vwap_y\n",
    "    \n",
    "    for q in np.unique(exo_df.index.quarter):\n",
    "        exo_df_slice = exo_df[(exo_df.index.year == y) & (exo_df.index.quarter == q)]\n",
    "        vwap = ((exo_df_slice.c * exo_df_slice.v).cumsum() / exo_df_slice.v.cumsum())\n",
    "\n",
    "        temp_df['vwap_qtr_{}_{}'.format(q, y)] = vwap\n",
    "        \n",
    "    for w in np.unique(exo_df.index.weekofyear):\n",
    "        exo_df_slice = exo_df[(exo_df.index.year == y) & (exo_df.index.weekofyear == w)]\n",
    "        vwap = ((exo_df_slice.c * exo_df_slice.v).cumsum() / exo_df_slice.v.cumsum())\n",
    "\n",
    "        temp_df['vwap_weekly_{}_{}'.format(w, y)] = vwap\n",
    "        \n",
    "    for m in np.unique(exo_df.index.month):\n",
    "        exo_df_slice = exo_df[(exo_df.index.year == y) & (exo_df.index.month == m)]\n",
    "        vwap = ((exo_df_slice.c * exo_df_slice.v).cumsum() / exo_df_slice.v.cumsum())\n",
    "\n",
    "        temp_df['vwap_monthly_{}_{}'.format(m, y)] = vwap\n",
    "        \n",
    "exo_df['vwap_weekly'] = temp_df.filter(regex='vwap_weekly').sum(axis=1)\n",
    "exo_df['vwap_monthly'] = temp_df.filter(regex='vwap_month').sum(axis=1)\n",
    "exo_df['vwap_quarterly'] = temp_df.filter(regex='vwap_qtr').sum(axis=1)\n",
    "exo_df['vwap_yearly'] = temp_df.filter(regex='vwap_year').sum(axis=1)\n",
    "\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(str('vhlo'))\n",
    "l.append('exec')\n",
    "\n",
    "#exo_df.drop(list(str('vhloc')), axis=1).iloc[700:1000:].plot();\n",
    "exo_df.drop(l, axis=1).iloc[-700:].plot(cmap='Vega10');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
