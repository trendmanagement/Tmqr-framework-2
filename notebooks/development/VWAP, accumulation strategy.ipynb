{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from tmqr.settings import *\n",
    "from tmqrfeed import DataManager\n",
    "from pymongo import MongoClient\n",
    "from tmqrindex.index_base import IndexBase\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "#import cufflinks as cf\n",
    "#cf.go_offline()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "#import matplotlib\n",
    "#%matplotlib notebook\n",
    "\n",
    "figsize(15,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (pipeline, preprocessing, ensemble, neighbors, linear_model, neural_network, cluster, metrics, decomposition,\n",
    "                     naive_bayes, calibration, svm, multioutput,\n",
    "                     feature_selection, discriminant_analysis, model_selection, multiclass\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGO_CONNSTR)\n",
    "db = client[MONGO_DB]\n",
    "\n",
    "dm = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exo_list(exo_filter='*', return_names=True):\n",
    "    \"\"\"\n",
    "    Return EXO list stored in MongoDB V2\n",
    "    :param exo_filter: '*' - include all, wildcard is allowed (like, 'ES_Bullish*')\n",
    "    :param return_names: if True returns names list of EXO, otherwize returns MongoDB data collection list\n",
    "    :return: list of EXO names\n",
    "    \"\"\"\n",
    "    re_val = exo_filter.replace('*','.*')\n",
    "\n",
    "    data = db['index_data'].find({'name': re.compile(re_val, re.IGNORECASE)})\n",
    "    if return_names:\n",
    "        return [exo['name'] for exo in data]\n",
    "    else:\n",
    "        return list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_fisher_transform(series, transform_with='arctanh'):\n",
    "    '\"transform_with\" options - \"tanh\", \"arctanh\"'\n",
    "    \n",
    "    # Centering the series\n",
    "    series = series.expanding().apply(lambda x: preprocessing.StandardScaler().fit_transform(x.reshape(-1, 1)\n",
    "                                                                                                          ).ravel()[-1])\n",
    "\n",
    "    # limiting it to -0.999 > x < 0.999\n",
    "    series = series.expanding().apply(lambda x: preprocessing.MinMaxScaler(feature_range=(-0.999,0.999)\n",
    "                                                                                        ).fit_transform(x.reshape(-1, 1)).ravel()[-1])\n",
    "\n",
    "    if transform_with == 'arctanh':\n",
    "        ft_ser = np.arctanh(series)\n",
    "        \n",
    "    elif transform_with == 'tanh':\n",
    "        ft_ser = np.tanh(series)\n",
    "        \n",
    "    return ft_ser"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def universal_fisher_transform(series, scaling_period, transform_with='arctanh'):\n",
    "    '\"transform_with\" options - \"tanh\", \"arctanh\"'\n",
    "    \n",
    "    # Centering the series\n",
    "    series = series.rolling(int(scaling_period/2)).apply(lambda x: \n",
    "                                                         preprocessing.StandardScaler().fit_transform(x.reshape(-1, 1)\n",
    "                                                                                                     ).ravel()[-1])\n",
    "\n",
    "    # limiting it to -0.999 > x < 0.999\n",
    "    series = series.rolling(int(scaling_period/2)).apply(lambda x: \n",
    "                                                         preprocessing.MinMaxScaler(feature_range=(-0.999,0.999)\n",
    "                                                                                   ).fit_transform(x.reshape(-1, 1)\n",
    "                                                                                                  ).ravel()[-1])\n",
    "\n",
    "    \n",
    "    #return series\n",
    "\n",
    "    if transform_with == 'arctanh':\n",
    "        ft_ser = np.arctanh(series)\n",
    "        #ft_ser += 0.25 * ft_ser.shift(1)\n",
    "        #ft_ser += 0.5 * ft_ser.shift(1)\n",
    "        \n",
    "    elif transform_with == 'tanh':\n",
    "        ft_ser = np.tanh(series)\n",
    "        #ft_ser += 0.25 * ft_ser.shift(1)\n",
    "        #ft_ser += 0.5 * ft_ser.shift(1)\n",
    "        \n",
    "    return ft_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exo_filter = 'neutralOnly'     # All \n",
    "exo_filter = '*'  # ES only\n",
    "#exo_filter = '*'  # ES Collars (incl Bearish, Bullish, BW and vanilla)\n",
    "\n",
    "exo_dict = {}\n",
    "for exo in get_exo_list(exo_filter, return_names=False):\n",
    "    idx = IndexBase.deserialize(dm, exo, as_readonly=True)\n",
    "    exo_dict[idx.index_name] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exo_name, exo in exo_dict.items():\n",
    "    exo_df = exo.data\n",
    "    \n",
    "    if len(exo_df) < 200:\n",
    "        print(\"{0:<70} [NODATA DataLen: {1}]\".format(exo.index_name, len(exo_df)))\n",
    "    elif (datetime.now().date() - exo_df.index.date[-1]).days > 4:\n",
    "        print(\"{0:<70} [DELAYED: LastDate: {1}]\".format(exo.index_name, exo_df.index[-1]))\n",
    "    else:\n",
    "        print(\"{0:<70} [OK]\".format(exo.index_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_df = exo_dict['US.6C_ContFutEOD'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwap = ((exo_df.c * exo_df.v).cumsum() / exo_df.v.cumsum())\n",
    "\n",
    "#vwap = (exo_df.c * exo_df.v).rolling(250).mean() / exo_df.v.rolling(250).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_df.c.plot()\n",
    "vwap.plot(label='VWAP', legend=True)\n",
    "exo_df.c.expanding().mean().plot(label='Expanding mean', legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BBands style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_df.c.plot()\n",
    "\n",
    "vwap.plot()\n",
    "(vwap + 2*vwap.expanding(20).std()).plot()\n",
    "(vwap - 2*vwap.expanding(20).std()).plot()\n",
    "(vwap + 4*vwap.expanding(20).std()).plot()\n",
    "(vwap - 4*vwap.expanding(20).std()).plot()\n",
    "(vwap + 6*vwap.expanding(20).std()).plot()\n",
    "(vwap - 6*vwap.expanding(20).std()).plot()\n",
    "(vwap + 8*vwap.expanding(20).std()).plot()\n",
    "(vwap - 8*vwap.expanding(20).std()).plot()\n",
    "(vwap + 10*vwap.expanding(20).std()).plot()\n",
    "(vwap - 10*vwap.expanding(20).std()).plot()\n",
    "\n",
    "plt.ylim([exo_df.c.min(), exo_df.c.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top/bottom finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONT FUT VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_rollingmax = exo_df.h.rolling(int(exo_df.h.size * 0.01)).max()\n",
    "low_rollingmin = exo_df.l.rolling(int(exo_df.l.size * 0.01)).min()\n",
    "\n",
    "topfinder_ser = pd.Series(index=exo_df.index)\n",
    "botfinder_ser = pd.Series(index=exo_df.index)\n",
    "\n",
    "highest_high = exo_df.h >= high_rollingmax\n",
    "lowest_low = exo_df.l <= low_rollingmin\n",
    "\n",
    "highest_high = highest_high[highest_high == True]\n",
    "lowest_low = lowest_low[lowest_low == True]\n",
    "\n",
    "for i in range(highest_high.size):\n",
    "    if highest_high[i] == True:\n",
    "        if i == 0:\n",
    "            midas_close = (exo_df.h.ix[:highest_high.index[i]] + exo_df.l.ix[:highest_high.index[i]]) / 2\n",
    "            midas_volume = exo_df.v.ix[:highest_high.index[i]]\n",
    "\n",
    "            price_volume_onstart = pd.Series((midas_close[0] * midas_volume[0]), index=midas_close.index)\n",
    "            volume_onstart = pd.Series(midas_volume[0], index=midas_close.index)\n",
    "\n",
    "            midas_vwap = (((midas_close * midas_volume).cumsum() - price_volume_onstart) / \n",
    "                          (midas_volume.cumsum() - volume_onstart))\n",
    "            \n",
    "            topfinder_ser[midas_vwap.index] = midas_vwap\n",
    "            \n",
    "        else:\n",
    "            midas_close = (exo_df.h.ix[highest_high.index[i-1]: highest_high.index[i]] + \n",
    "                           exo_df.l.ix[highest_high.index[i-1]: highest_high.index[i]]) / 2\n",
    "            \n",
    "            midas_volume = exo_df.v.ix[highest_high.index[i-1]: highest_high.index[i]]\n",
    "\n",
    "            price_volume_onstart = pd.Series((midas_close[0] * midas_volume[0]), index=midas_close.index)\n",
    "            volume_onstart = pd.Series(midas_volume[0], index=midas_close.index)\n",
    "\n",
    "            midas_vwap = (((midas_close * midas_volume).cumsum() - price_volume_onstart) / \n",
    "                          (midas_volume.cumsum() - volume_onstart))\n",
    "\n",
    "            \n",
    "            topfinder_ser[midas_vwap.index] = midas_vwap\n",
    "        \n",
    "\n",
    "for i in range(lowest_low.size):\n",
    "    if lowest_low[i] == True:\n",
    "        if i == 0:\n",
    "            midas_close = (exo_df.h.ix[:lowest_low.index[i]] + exo_df.l.ix[:lowest_low.index[i]]) / 2\n",
    "            midas_volume = exo_df.v.ix[:lowest_low.index[i]]\n",
    "\n",
    "            price_volume_onstart = pd.Series((midas_close[0] * midas_volume[0]), index=midas_close.index)\n",
    "            volume_onstart = pd.Series(midas_volume[0], index=midas_close.index)\n",
    "\n",
    "            midas_vwap = (((midas_close * midas_volume).cumsum() - price_volume_onstart) / \n",
    "                          (midas_volume.cumsum() - volume_onstart))\n",
    "            \n",
    "            topfinder_ser[midas_vwap.index] = midas_vwap\n",
    "            \n",
    "        else:\n",
    "            midas_close = (exo_df.h.ix[lowest_low.index[i-1]: lowest_low.index[i]] + \n",
    "                           exo_df.l.ix[lowest_low.index[i-1]: lowest_low.index[i]]) / 2\n",
    "\n",
    "            midas_volume = exo_df.v.ix[lowest_low.index[i-1]: lowest_low.index[i]]\n",
    "\n",
    "            price_volume_onstart = pd.Series((midas_close[0] * midas_volume[0]), index=midas_close.index)\n",
    "            volume_onstart = pd.Series(midas_volume[0], index=midas_close.index)\n",
    "\n",
    "            midas_vwap = (((midas_close * midas_volume).cumsum() - price_volume_onstart) / \n",
    "                          (midas_volume.cumsum() - volume_onstart))\n",
    "\n",
    "            \n",
    "            botfinder_ser[midas_vwap.index] = midas_vwap\n",
    "        \n",
    "'''if lowest_low[i] == True:\n",
    "    midas_close = exo_df.c.ix[highest_high.index[i]:]#.iloc[:i]\n",
    "    midas_volume = exo_df.v.ix[highest_high.index[i]:]#.iloc[:i]\n",
    "\n",
    "    price_volume_onstart = pd.Series((midas_close[0] * midas_volume[0]), index=midas_close.index)\n",
    "    volume_onstart = pd.Series(midas_volume[0], index=midas_close.index)\n",
    "\n",
    "    midas_vwap = ((midas_close * midas_volume).cumsum() - price_volume_onstart) / (midas_volume.cumsum() - volume_onstart)\n",
    "\n",
    "    botfinder_ser[midas_vwap.index] = midas_vwap'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exo_df.c.iloc[-500:].plot()\n",
    "((exo_df.h + exo_df.l)/2).iloc[-500:].plot()\n",
    "\n",
    "#low_rollingmin.iloc[-500:].plot()\n",
    "botfinder_ser.ffill().iloc[-500:].plot()\n",
    "#topfinder_ser.ffill().iloc[-500:].plot();\n",
    "topfinder_ser.ffill().iloc[-500:].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_df.c.iloc[:].plot()\n",
    "#botfinder_ser.iloc[-500:].plot()\n",
    "#topfinder_ser.iloc[-500:].plot();\n",
    "\n",
    "(topfinder_ser - botfinder_ser).ffill().iloc[:].plot(secondary_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((exo_df.h + exo_df.l)/2).iloc[:].plot()\n",
    "\n",
    "x = pd.Series(np.mean([exo_df.h, exo_df.l], axis=0), index=exo_df.index)\n",
    "\n",
    "pd.Series(np.mean([exo_df.h, exo_df.l], axis=0), index=exo_df.index).iloc[:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly VWAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in np.unique(exo_df.index.year):\n",
    "    exo_df_slice = exo_df[exo_df.index.year == y]\n",
    "    vwap_y = ((exo_df_slice.c * exo_df_slice.v).cumsum() / exo_df_slice.v.cumsum())\n",
    "\n",
    "    exo_df['vwap_yearly_{}'.format(y)] = vwap_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in np.unique(exo_df.index.year):\n",
    "    for q in np.unique(exo_df.index.quarter):\n",
    "        exo_df_slice = exo_df[(exo_df.index.year == y) & (exo_df.index.quarter == q)]\n",
    "        vwap = ((exo_df_slice.c * exo_df_slice.v).cumsum() / exo_df_slice.v.cumsum())\n",
    "\n",
    "        exo_df['vwap_qtr_{}_{}'.format(q, y)] = vwap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in np.unique(exo_df.index.year):\n",
    "    for w in np.unique(exo_df.index.weekofyear):\n",
    "        exo_df_slice = exo_df[(exo_df.index.year == y) & (exo_df.index.weekofyear == w)]\n",
    "        vwap = ((exo_df_slice.c * exo_df_slice.v).cumsum() / exo_df_slice.v.cumsum())\n",
    "\n",
    "        exo_df['vwap_weekly_{}_{}'.format(w, y)] = vwap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in np.unique(exo_df.index.year):\n",
    "    for m in np.unique(exo_df.index.month):\n",
    "        exo_df_slice = exo_df[(exo_df.index.year == y) & (exo_df.index.month == m)]\n",
    "        vwap = ((exo_df_slice.c * exo_df_slice.v).cumsum() / exo_df_slice.v.cumsum())\n",
    "\n",
    "        exo_df['vwap_monthly_{}_{}'.format(m, y)] = vwap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_df.c.iloc[-200:].plot(legend=False);\n",
    "exo_df.filter(regex='vwap_weekly').sum(axis=1).iloc[-200:].plot(legend=False);\n",
    "exo_df.filter(regex='vwap_month').sum(axis=1).iloc[-200:].plot(legend=False);\n",
    "exo_df.filter(regex='vwap_q').sum(axis=1).iloc[-200:].plot(legend=False);\n",
    "exo_df.filter(regex='vwap_y').sum(axis=1).iloc[-200:].plot(legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exo_df.filter(regex='vwap_yearly').sum(axis=1).plot()\n",
    "#exo_df.filter(regex='vwap_qtr').plot(cmap='jet')\n",
    "#exo_df.filter(regex='vwap_weekly').iloc[-200:].plot(cmap='jet', legend=False)\n",
    "exo_df.filter(regex='vwap_month').iloc[-800:].plot(c='g', legend=False)\n",
    "exo_df.c.iloc[-800:].plot()\n",
    "\n",
    "#(exo_df.c - exo_df.filter(regex='vwap_yearly').sum(axis=1)).plot(secondary_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_vwap_diff = (exo_df.c - exo_df.filter(regex='vwap_yearly').sum(axis=1))\n",
    "#c_vwap_diff =  c_vwap_diff - c_vwap_diff.expanding().mean()\n",
    "c_vwap_diff = (exo_df.c - exo_df.filter(regex='vwap_qtr').sum(axis=1))\n",
    "\n",
    "c_vwap_diff_expmedian = c_vwap_diff.expanding().median()\n",
    "\n",
    "c_vwap_diff.plot(label='close - vwap', legend=True)\n",
    "c_vwap_diff.expanding().median().plot(label='median(close - vwap)', legend=True)\n",
    "\n",
    "\n",
    "#(c_vwap_diff_expmedian + c_vwap_diff.std()*2).plot(label='+2 sigma', legend=True)\n",
    "#(c_vwap_diff_expmedian - c_vwap_diff.std()*2).plot(label='-2 sigma', legend=True)\n",
    "\n",
    "(c_vwap_diff_expmedian + c_vwap_diff.std()*0.5).plot(label='+0.5 sigma', legend=True)\n",
    "(c_vwap_diff_expmedian - c_vwap_diff.std()*0.5).plot(label='-0.5 sigma', legend=True)\n",
    "#exo_df.filter(regex='vwap_yearly').sum(axis=1).plot(label='VWAP yearly', legend=True, secondary_y=True, alpha=0.25)\n",
    "\n",
    "exo_df.c.plot(secondary_y=True, label='close', legend=True, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_vwap_diff.skew())\n",
    "print(c_vwap_diff.kurt())\n",
    "c_vwap_diff.plot.kde()\n",
    "axvline(c_vwap_diff.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "sm.qqplot(c_vwap_diff.dropna(), fit=True, line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulation strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_df = exo_dict['US.HO_ContFutEOD'].data\n",
    "\n",
    "acc_df = pd.DataFrame()\n",
    "acc_df['c'] = exo_df.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new week trigger\n",
    "# shift -1 = new week is on monday\n",
    "# shift 1 = new week is on friday\n",
    "acc_df.loc[acc_df.index.week != acc_df.index.shift(-1, 'B').week, 'new_week'] = True\n",
    "acc_df['week_id'] = acc_df.new_week.cumsum().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarterly VWAP\n",
    "for y in np.unique(exo_df.index.year):\n",
    "    for q in np.unique(exo_df.index.quarter):\n",
    "        exo_df_slice = exo_df[(exo_df.index.year == y) & (exo_df.index.quarter == q)]\n",
    "        vwap_qtr = ((exo_df_slice.c * exo_df_slice.v).cumsum() / exo_df_slice.v.cumsum())\n",
    "\n",
    "        exo_df['vwap_qtr_{}_{}'.format(q, y)] = vwap_qtr\n",
    "        \n",
    "c_vwap_diff = (exo_df.c - exo_df.filter(regex='vwap_qtr').sum(axis=1))\n",
    "\n",
    "acc_df['close_vwap_diff'] = c_vwap_diff\n",
    "\n",
    "acc_df['close_vwap_diff_+05 sigma'] = acc_df['close_vwap_diff'].expanding().median() + acc_df['close_vwap_diff'].std()*0.5\n",
    "acc_df['close_vwap_diff_-05 sigma'] = acc_df['close_vwap_diff'].expanding().median() - acc_df['close_vwap_diff'].std()*0.5\n",
    "\n",
    "# Mark the regimes \n",
    "#  over weight = 2, neutral = 0 or underweight = 1\n",
    "regime_0_condition = ((acc_df['close_vwap_diff'] < acc_df['close_vwap_diff_+05 sigma']) & \n",
    "                      (acc_df['close_vwap_diff'] > acc_df['close_vwap_diff_-05 sigma']))\n",
    "\n",
    "acc_df.loc[regime_0_condition, 'regime_0'] = True\n",
    "acc_df['regime_0'].fillna(False, inplace=True)\n",
    "\n",
    "\n",
    "regime_1_condition = (acc_df['close_vwap_diff'] < acc_df['close_vwap_diff_-05 sigma'])\n",
    "\n",
    "acc_df.loc[regime_1_condition, 'regime_1'] = True\n",
    "acc_df['regime_1'].fillna(False, inplace=True)\n",
    "\n",
    "\n",
    "regime_2_condition = (acc_df['close_vwap_diff'] > acc_df['close_vwap_diff_+05 sigma'])\n",
    "\n",
    "acc_df.loc[regime_2_condition, 'regime_2'] = True\n",
    "acc_df['regime_2'].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading logic\n",
    "# 1) set weekly quantity of units to sell \n",
    "n_units_per_week = 100\n",
    "\n",
    "n_units_per_day = n_units_per_week / 10\n",
    "\n",
    "# 2) set multipliers for defined regimes\n",
    "reg_0_mul = n_units_per_day * 1\n",
    "reg_1_mul = n_units_per_day\n",
    "reg_2_mul = n_units_per_day * 5\n",
    "\n",
    "\n",
    "acc_df['units'] = np.nan\n",
    "acc_df['buy_n_units'] = np.nan\n",
    "acc_df['sell_n_units'] = np.nan\n",
    "\n",
    "acc_df.loc[acc_df.regime_0 == True, 'units'] = reg_0_mul\n",
    "acc_df.loc[acc_df.regime_1 == True, 'units'] = reg_1_mul\n",
    "acc_df.loc[acc_df.regime_2 == True, 'units'] = reg_2_mul\n",
    "\n",
    "'''for week_id in acc_df.week_id.unique():\n",
    "    # Get cumulative sum of units for every week id\n",
    "    units_slice = acc_df.copy().query('week_id == {}'.format(week_id)).units.cumsum()\n",
    "    # Limit this sum\n",
    "    units_slice.loc[units_slice > n_units_per_week] = n_units_per_week\n",
    "    \n",
    "    acc_df.loc[units_slice.index, 'units'] = units_slice'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.units.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('N units_per_week', n_units_per_week)\n",
    "print('N  units per day', n_units_per_day)\n",
    "\n",
    "print('Regime 0 multiplier', reg_0_mul)\n",
    "print('Regime 1 multiplier', reg_1_mul)\n",
    "print('Regime 2 multiplier', reg_2_mul)\n",
    "\n",
    "acc_df.c.plot(label='close', legend=True)\n",
    "acc_df.units.plot(secondary_y=True, label='units', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.units.iloc[:100].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(acc_df.c.diff() * (acc_df.units*1)).cumsum().plot(label='close * units', legend=True)\n",
    "(acc_df.c.diff() *1).cumsum().plot(secondary_y=True, label='close', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.units.cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
